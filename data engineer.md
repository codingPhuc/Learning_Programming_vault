mentions 1 : 
- Strong interest in Data Science, particularly in the data engineering field
    
- Proficiency in Python programming, with a focus on data manipulation and analysis
    
- Experience with PySpark for large-scale data processing
    
- Strong knowledge of SQL and relational databases, including advanced query authoring
    
- Familiarity with end-to-end BI solution development, including data warehousing concepts
    
- Experience with data visualization tools (preferably Power BI) is a plus
    
- Knowledge of cloud platforms (e.g., AWS, Azure, GCP) for data engineering tasks is a plus
    
- Strong analytical thinking and problem-solving skills
    
- Proactive attitude with effective self-learning and research skills
    
- Good English language skills for video conferencing and face-to-face communication
    
- Ability to thrive in a fast-paced work environment


mention 2 : 
- **Python** (Fluency required)
- **SQL** (Fluency required)
- **Data Engineering** (At least two years of working experience)
- **Informatica** (Experience with ETL migration from Informatica to Snowflake)
- **Snowflake** (Experience is a plus)
- **ETL (Extract, Transform, Load)** (Experience with migration projects)
- **Banking, Investment, or Risk Management** (Experience in these areas is a plus)
- **LLM (Large Language Models)** (Newer approaches for improving productivity)

mention 3 : 
- **Power BI (PBI)**:
    
    - **PBI Desktop** (Advanced level)
    - **PBI Paginated Reports**
    - **PBI Service (PowerBI Cloud Service)**
    - **PowerBI Semantic Modeling**
    - **PowerBI Report Design and Architecture**
    - **PBI Report Development Proficiency**
    - **PBI Report Performance Optimization**
- **SQL**:
    
    - **SQL for Data Analysis**
    - **DAX (Data Analysis Expressions)** for data analysis and visualization
- **Data Governance and Security**:
    
    - Knowledge of data management, governance, and implementing security protocols in PowerBI and reports.
- **Leadership and Mentoring**:
    
    - Experience leading teams and providing mentorship.
- **Problem-Solving Skills**:
    
    - Ability to address challenges related to report optimization and business intelligence architecture.
- **English Communication**:
    
    - Strong English communication skills are required.


menction 3 : 
- **Azure Platform**:
    
    - **Azure Data Factory (ADF)** for orchestrating and automating data workflows
    - **Azure Databricks** for scalable data processing and analytics
    - **Azure SQL Data Warehouse (DW)**
    - **Azure Functions** for serverless architecture
    - **Azure Blob Storage** for scalable and secure data storage
- **Data Lakehouse Architecture**:
    
    - Familiarity with concepts, principles, and best practices of the Data Lakehouse architecture
- **ETL Processes**:
    
    - Designing, developing, and optimizing ETL (Extract, Transform, Load) pipelines for various data sources
- **Delta Lake**:
    
    - Experience with **Delta Lake** for managing large data workloads efficiently
- **Database Systems**:
    
    - Experience with **Relational Databases** (e.g., PostgreSQL, MySQL)
    - Experience with **NoSQL Databases** (e.g., MongoDB, Cassandra)
- **Programming & Scripting**:
    
    - Proficiency in **Python** for data manipulation, automation, and scripting
- **Real-time Data Processing**:
    
    - Knowledge of real-time data processing frameworks such as **Apache Kafka** and **Apache Flink**
- **Data Modeling**:
    
    - Building and maintaining data models, ensuring data integrity and quality
- **Data Storage & Optimization**:
    
    - Implementing and optimizing data storage solutions for scalability, reliability, and security
- **Data Visualization Tools**:
    
    - Familiarity with tools such as **Tableau** and **Power BI** for data visualization
- **General Cloud Knowledge**:
    
    - Hands-on experience with **serverless architecture** and optimizing performance, reliability, and cost-effectiveness


mentions 4 : 
**Mô tả công việc:**

- Vận hành, bảo trì và tối ưu hóa các luồng dữ liệu hiện có.
- Tham gia vào quy trình ETL, làm sạch dữ liệu, phân tích dữ liệu, triển khai và trực quan hóa.
- Phân tích dữ liệu thô và hỗ trợ cải tiến chất lượng dữ liệu.
- Theo dõi hoạt động dữ liệu để phát hiện vấn đề và đưa ra giải pháp.
- Nghiên cứu và áp dụng công cụ xử lý Big Data và Data Mining để đề xuất giải pháp giá trị.
- Cập nhật, nâng cấp và tự động hóa quy trình dữ liệu.
- Phân tích các yêu cầu nghiệp vụ từ các phòng ban.
- Thực hiện các nhiệm vụ khác theo yêu cầu của cấp trên.

**Yêu cầu ứng viên:**

- Tốt nghiệp chuyên ngành liên quan đến Khoa học Máy tính, Thống kê, Tin học, Hệ thống Thông tin.
- Kinh nghiệm ít nhất 1 năm ở vị trí tương đương.
- **Bắt buộc**: Kinh nghiệm sử dụng **Python** và **PowerBI**.
- Có kiến thức về **SPSS**, **R**, **MySQL** là điểm cộng.
- Thành thạo một trong các công cụ: **Qlikview**, **Tableau**, **IBM Cognos**, **Google Data Studio**.
- Hiểu biết về tối ưu hóa luồng dữ liệu: Landing Zone, Working Zone.
- Kiến thức cơ bản về **Data Mining** và **Machine Learning**.
- Kỹ năng mô tả dữ liệu, xây dựng dashboard và scorecard.
- Khả năng đa nhiệm và làm việc độc lập.
- Trung thực, chăm chỉ, sáng tạo, và có tinh thần học hỏi.
- Biết tiếng Anh là lợi thế.


mention 5 : 
**osition: Data Engineer (BI Developer)**

**Location:** [Location]

**Role Overview:** We are seeking a talented Data Engineer (BI Developer) to join our team. In this role, you will be responsible for designing, developing, and maintaining our data platform system. You will collaborate with both internal and client teams to ensure data is prepared and delivered optimally for business decision-making.

**Key Responsibilities:**

- **Build Data Platform Solution:** Collect, process, and standardize data from various sources into a centralized data platform.
- **Build and Maintain Data Warehouses:** Develop and manage data warehouses and ETL (Extract, Transform, Load) systems to ensure data accuracy and availability.
- **Optimize Performance:** Enhance BI system performance and data processes for fast response times and high efficiency.
- **Data Integration:** Work with various data sources to integrate and consolidate data, ensuring quality and integrity.
- **Technical Support and Training:** Provide support and training for teams and end-users on BI tools and reporting.

**Candidate Requirements:**

- **Experience:** Minimum of 1-2 years in a Data Engineer, BI Developer, or similar role, with hands-on experience in developing BI solutions and managing data.
    
- **Technical Skills:**
    
    - **Core Technical Skills:**
        - **Cloud Platforms Proficiency:** Experience with at least one of the following:
            - **Azure:** Knowledge of Azure Data Lake Storage, Azure Synapse Analytics, Azure Data Factory, and Azure Databricks.
            - **AWS:** Familiarity with Amazon S3, Amazon Redshift, AWS Glue, and AWS Lambda.
            - **Databricks:** Proficiency in using Databricks for big data processing and analytics, including Apache Spark.
    - **Data Modeling and Database Management:**
        - Strong understanding of SQL and NoSQL databases.
        - Experience with data warehousing solutions and database optimization.
    - **Data Integration and ETL Processes:**
        - Proficiency in designing and managing ETL pipelines.
    - **Programming Skills:**
        - Proficiency in Python, Spark Notebook, or Scala for data manipulation and automation.
- **Additional Skills:**
    
    - **Data Security and Compliance:** Understanding of data governance, security best practices, and compliance requirements.
    - **DevOps and Automation:** Familiarity with CI/CD pipelines.
    - **Machine Learning and Analytics:** Basic knowledge of machine learning principles and tools for data analysis.
- **Soft Skills:**
    
    - Strong problem-solving abilities.
    - Effective communication and teamwork skills.
    - Excellent presentation skills with the ability to explain complex issues clearly.
- **Education:** Bachelor’s degree in Computer Science, Engineering, Mathematics, or a related field.
    

**Benefits:**

- **Personal Development:**
    - Opportunities for career growth through training and hands-on projects.
    - Support for international professional certification costs.
- **Attractive Benefits:**
    - Competitive compensation package including health insurance, paid leave, and other benefits.
    - Performance reviews annually.
    - 13th-month salary.
    - Teambuilding, company trips, tea breaks, and knowledge-sharing events.
- **Flexible Work:**
    - Flexible working policies.
    - Working hours: Monday - Friday, 9:00 AM – 06:00 PM.
    - 16 vacation days per year and statutory holidays, including Christmas.

**Application Process:** [Instructions on how to apply, if applicable]
mentions 6 : 
The required skills for this opportunity at FPT Software HCM include:

1. **Final-year student or graduate** in IT, Engineering, Mathematics, or Natural Sciences.
2. **Database experience** (preferred).
3. **Problem-solving experience** in algorithms, data processing, AI/ML, or software deployment.
4. **Self-learning ability** and resilience under high work pressure.
5. **English or Japanese proficiency** (advantageous).

These skills are essential to apply for the Data Engineer training program and participate in software development projects at the company.

mentions  7 : 
### Required Skills/Experience:

1. **Bachelor's degree** in Computer Science or a related field.
2. Strong **SQL and NoSQL** knowledge.
3. Proficiency in **Python** and **Java** (Scala is a plus).
4. Experience with **RDBMS** (e.g., SQL Server, MySQL, Oracle).
5. Knowledge of **cloud platforms** like AWS, Azure, or Google Cloud.
6. Familiarity with **reporting tools** (SSRS, Power BI is preferred).
7. Willingness to learn new technologies.
8. Strong **English communication skills**.
**Technical Skills:**

1. **3+ years** of experience as a Data Engineer.
2. Proficient in **Advanced SQL** and **Python**.
3. Experience with **SQL** and **NoSQL** databases.
4. Strong **Cloud-based Data Engineering** experience (preferably with GCP, but AWS/Azure experience is acceptable).
5. Familiarity with **Docker/Kubernetes** (optional but a plus).
6. Experience with **ETL frameworks/tools** like Airflow.
7. Knowledge of **CI/CD pipelines** and developing data solutions (Data Warehouse, Data Lake).
8. Comfortable working with **different data types** (structured, semi-structured, real-time, etc.).

**Non-Technical Skills:**

1. Strong **communication skills** (both verbal and written).
2. **Proactive problem-solving** abilities, attention to detail, and a process-driven mindset.

These qualifications are vital for working on data pipelines, cloud platforms, and DevOps automation.
These are key qualifications to succeed in the role of building large-scale data systems and gaining experience with cloud platforms and data tools.
mentions 8 : 
### Tóm tắt yêu cầu công việc:

- **Trình độ**: Cử nhân Khoa học Máy tính hoặc ngành liên quan.
- **Kỹ năng chính**:
    - Thành thạo **SQL**, **NoSQL**, **Python**, **Java** (có Scala là điểm cộng).
    - Kinh nghiệm với các **RDBMS** như SQL Server, MySQL, Oracle.
    - Hiểu biết về **nền tảng đám mây** (AWS, Azure, Google Cloud).
    - Kiến thức về các công cụ báo cáo như **SSRS**, **Power BI**.
- **Khả năng**: Kỹ năng giao tiếp tiếng Anh tốt và sẵn sàng học công nghệ mới.

**Lịch làm việc**:

- Thứ Hai - Thứ Sáu: Sáng và Chiều.
- Không yêu cầu kinh nghiệm làm việc.
- Yêu cầu có **visa làm việc** cho vị trí này.



- Analytical thinking
- Apache Flink
- Apache Kafka
- Apache Spark
- AWS
- AWS Glue
- AWS Lambda
- Azure
- Azure Blob Storage
- Azure Data Factory (ADF)
- Azure Data Lake Storage
- Azure Databricks
- Azure Functions
- Azure SQL Data Warehouse (DW)
- Azure Synapse Analytics
- Banking, Investment, or Risk Management
- CI/CD pipelines
- Cloud Platforms Proficiency
- Cloud platforms
- DAX (Data Analysis Expressions)
- Data Analysis
- Data Engineering
- Data Governance
- Data Governance and Security
- Data Integration
- Data Lakehouse Architecture
- Data Mining
- Data Modeling
- Data Security and Compliance
- Data Storage & Optimization
- Data Visualization Tools
- Data Warehousing
- Databricks
- Delta Lake
- DevOps and Automation
- English Communication
- English language skills
- ETL (Extract, Transform, Load)
- Google Data Studio
- IBM Cognos
- Informatica
- LLM (Large Language Models)
- Leadership and Mentoring
- Machine Learning
- MySQL
- NoSQL databases
- PBI Desktop
- PBI Paginated Reports
- PBI Report Development Proficiency
- PBI Report Performance Optimization
- PBI Report Design and Architecture
- PBI Semantic Modeling
- PBI Service (PowerBI Cloud Service)
- Power BI
- PowerBI
- Problem-Solving Skills
- Proactive attitude
- PySpark
- Python
- Qlikview
- R
- Relational databases
- Research skills
- SPSS
- SQL
- SQL for Data Analysis
- Snowflake
- Spark Notebook
- Tableau


To sort the skills into those that need to be learned the most and those that don't, I'll categorize them based on the frequency of their mentions across the job posts. Skills mentioned more frequently will be considered more important to learn.

### Skills Mentioned Multiple Times (High Priority):

1. **Python** (Mentioned in 1, 2, 4, 5) a
2. **SQL** (Mentioned in 1, 2, 3, 5) x
3. **Data Engineering** (Mentioned in 1, 2, 5) x
4. **ETL (Extract, Transform, Load)** (Mentioned in 2, 4, 5) 
5. **Power BI** (Mentioned in 1, 3, 4) 
6. **Cloud Platforms** (AWS, Azure, GCP) (Mentioned in 1, 5)
7. **Data Warehousing** (Mentioned in 1, 4, 5)
8. **Data Visualization Tools** (Power BI, Tableau) (Mentioned in 1, 4, 5)
9. **Problem-Solving Skills** (Mentioned in 1, 3, 5)
10. **English Communication** (Mentioned in 1, 3, 4) x 




























Here are the skills listed in descending order based on the number of mentions across the job descriptions:

1. **Python** - Mentioned in most descriptions, a core skill for data manipulation and automation.
2. **SQL** - Required for data analysis, relational database management, and query writing.
3. **Data Engineering** - A primary role focus, with extensive mention of ETL, cloud platforms, and large-scale data processing.
4. **Cloud Platforms (AWS, Azure, GCP)** - A key skill for handling data engineering tasks in the cloud environment.
5. **Power BI** - Specifically for data visualization, with a focus on report development and optimization.
6. **ETL (Extract, Transform, Load)** - Mentioned frequently in relation to data pipeline design, management, and optimization.
7. **NoSQL** - Required for working with databases like MongoDB or Cassandra alongside SQL.
8. **Data Warehousing** - Important for building and maintaining centralized data platforms.
9. **Data Visualization Tools** - Power BI, Tableau, and similar tools are necessary for reporting and analysis.
10. **Problem-Solving Skills** - Valued across roles for addressing challenges in data systems and business intelligence.
11. **Data Modeling** - Needed for ensuring data integrity and supporting BI processes.
12. **SPSS, R** - Mentioned as additional skills for specific roles, supporting statistical analysis and data handling.
13. **Data Governance and Security** - Required knowledge for managing data, especially in BI and cloud environments.
14. **Leadership and Mentoring** - Relevant for senior roles, particularly in BI development and report design.
15. **Machine Learning** - Basic knowledge mentioned as a plus for some roles.
16. **Java/Scala** - Java is required in some roles, while Scala is considered a bonus.
17. **Delta Lake** - Important for managing large data workloads efficiently.
18. **Apache Kafka/Apache Flink** - Useful for real-time data processing tasks.
19. **CI/CD Pipelines** - Valued in data engineering roles, particularly in the cloud context.
20. **Informatica** - Specific to ETL migration projects.
21. **Qlikview, Tableau, IBM Cognos, Google Data Studio** - Mentioned as additional BI tools for specific roles.
22. **Docker/Kubernetes** - Optional but beneficial for working with containers and cloud deployments.
23. **RDBMS (SQL Server, MySQL, Oracle)** - Specific to data engineering roles dealing with relational databases.
24. **DAX (Data Analysis Expressions)** - Used in Power BI for data analysis and reporting.
25. **English/Japanese Proficiency** - Required for communication in international teams.










